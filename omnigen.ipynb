{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/ComfyUI\n",
    "\n",
    "import os, json, requests, random, time\n",
    "from urllib.parse import urlsplit\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from nodes import load_custom_node\n",
    "from nodes import NODE_CLASS_MAPPINGS\n",
    "\n",
    "load_custom_node(\"/content/ComfyUI/custom_nodes/ComfyUI-OmniGen\")\n",
    "\n",
    "LoadImage = NODE_CLASS_MAPPINGS[\"LoadImage\"]()\n",
    "ailab_OmniGen = NODE_CLASS_MAPPINGS[\"ailab_OmniGen\"]()\n",
    "\n",
    "def download_file(url, save_dir, file_name):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    file_suffix = os.path.splitext(urlsplit(url).path)[1]\n",
    "    file_name_with_suffix = file_name + file_suffix\n",
    "    file_path = os.path.join(save_dir, file_name_with_suffix)\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    return file_path\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate(input):\n",
    "    values = input[\"input\"]\n",
    "\n",
    "    image_1=values['image_1']\n",
    "    if image_1:\n",
    "        image_1=download_file(url=image_1, save_dir='/content/ComfyUI/input', file_name='image_1')\n",
    "        image_1, _ = LoadImage.load_image(image_1)\n",
    "    else:\n",
    "        image_1 = None\n",
    "    image_2=values['image_2']\n",
    "    if image_2:\n",
    "        image_2=download_file(url=image_2, save_dir='/content/ComfyUI/input', file_name='image_2')\n",
    "        image_2, _ = LoadImage.load_image(image_2)\n",
    "    else:\n",
    "        image_2 = None\n",
    "    image_3=values['image_3']\n",
    "    if image_3:\n",
    "        image_3=download_file(url=image_3, save_dir='/content/ComfyUI/input', file_name='image_3')\n",
    "        image_3, _ = LoadImage.load_image(image_3)\n",
    "    else:\n",
    "        image_3 = None\n",
    "    prompt = values['prompt']\n",
    "    num_inference_steps = values['num_inference_steps']\n",
    "    guidance_scale = values['guidance_scale']\n",
    "    img_guidance_scale = values['img_guidance_scale']\n",
    "    max_input_image_size = values['max_input_image_size']\n",
    "    separate_cfg_infer = values['separate_cfg_infer']\n",
    "    offload_model = values['offload_model']\n",
    "    use_input_image_size_as_output = values['use_input_image_size_as_output']\n",
    "    width = values['width']\n",
    "    height = values['height']\n",
    "    seed = values['seed']\n",
    "\n",
    "    if seed == 0:\n",
    "        random.seed(int(time.time()))\n",
    "        seed = random.randint(0, 18446744073709551615)\n",
    "\n",
    "    image = ailab_OmniGen.generation(prompt, num_inference_steps, guidance_scale, img_guidance_scale, max_input_image_size, separate_cfg_infer, offload_model, use_input_image_size_as_output, width, height, seed, image_1=image_1, image_2=image_2, image_3=image_3)[0]\n",
    "    return Image.fromarray(np.array(image*255, dtype=np.uint8)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = { \n",
    "    \"input\": {\n",
    "        \"image_1\": \"https://litter.catbox.moe/j0onz6.jpg\",\n",
    "        \"image_2\": \"https://litter.catbox.moe/t2xbql.webp\",\n",
    "        \"image_3\": \"\",\n",
    "        \"prompt\": \"A blond woman in wearing a long pink dress standing in a park. A woman is image_1 The pink dress is image_2.\",\n",
    "        \"guidance_scale\": 3.5,\n",
    "        \"img_guidance_scale\": 1.8,\n",
    "        \"num_inference_steps\": 50,\n",
    "        \"separate_cfg_infer\": True,\n",
    "        \"offload_model\": False,\n",
    "        \"use_input_image_size_as_output\": False,\n",
    "        \"width\": 1024,\n",
    "        \"height\": 1024,\n",
    "        \"seed\": 67551597694014,\n",
    "        \"max_input_image_size\": 1024\n",
    "    }\n",
    "}\n",
    "image = generate(input)\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComfyUI-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
